

root@node002:~/bert_tf2# bash scripts/run_pretraining_lamb.sh 60 10 8 7.5e-4 5e-4 fp16 true 2 2000 200 7820 100 64 192 large
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
Container nvidia build =  19902717
Saving checkpoints to /results/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840_230203055722
Logs written to /results/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840_230203055722/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840.230203055722.log
+ bash scripts/run_pretraining_lamb_phase1.sh 60 10 8 7.500000e-04 5.000000e-04 fp16 true 2 2000 200 7820 100 64 192 large
+ tee -a /results/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840_230203055722/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840.230203055722.log
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
Container nvidia build =  19902717
XLA activated
2023-02-03 05:57:22.750717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-02-03 05:57:22.750717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported).
 The versions of TensorFlow you are currently using is 2.4.0 and is not supported.
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version.
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
2023-02-03 05:57:24.271637: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported).
 The versions of TensorFlow you are currently using is 2.4.0 and is not supported.
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version.
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
2023-02-03 05:57:24.272523: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-02-03 05:57:24.272878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-02-03 05:57:24.273830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-02-03 05:57:24.522574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Found device 0 with properties:
pciBusID: 0000:af:00.0 name: NVIDIA A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.45GiB deviceMemoryBandwidth: 1.41TiB/s
2023-02-03 05:57:24.525978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Found device 1 with properties:
pciBusID: 0000:d8:00.0 name: NVIDIA A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.45GiB deviceMemoryBandwidth: 1.41TiB/s
2023-02-03 05:57:24.526004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-02-03 05:57:24.528315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Found device 0 with properties:
pciBusID: 0000:af:00.0 name: NVIDIA A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.45GiB deviceMemoryBandwidth: 1.41TiB/s
2023-02-03 05:57:24.530068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Found device 1 with properties:
pciBusID: 0000:d8:00.0 name: NVIDIA A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.45GiB deviceMemoryBandwidth: 1.41TiB/s
2023-02-03 05:57:24.530109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-02-03 05:57:24.531024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 05:57:24.531097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-02-03 05:57:24.532429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-02-03 05:57:24.532792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-02-03 05:57:24.536585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 05:57:24.536614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-02-03 05:57:24.536645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-02-03 05:57:24.537630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-02-03 05:57:24.537767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-02-03 05:57:24.537927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-02-03 05:57:24.538275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-02-03 05:57:24.543475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-02-03 05:57:24.544002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1888] Adding visible gpu devices: 0, 1
2023-02-03 05:57:24.544653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-02-03 05:57:24.544783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-02-03 05:57:24.551055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1888] Adding visible gpu devices: 0, 1
2023-02-03 05:57:24.768149: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-02-03 05:57:24.770066: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0
2023-02-03 05:57:24.772051: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
I0203 05:57:24.771905 140737349957440 device_compatibility_check.py:126] Mixed precision compatibility check (mixed_float16): OK
Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale
W0203 05:57:24.772253 140737349957440 deprecation.py:333] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale
2023-02-03 05:57:24.773772: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK
Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0
I0203 05:57:24.775626 140737349957440 device_compatibility_check.py:126] Mixed precision compatibility check (mixed_float16): OK
Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale
W0203 05:57:24.775983 140737349957440 deprecation.py:333] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale
2023-02-03 05:57:24.800199: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-02-03 05:57:24.800293: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-02-03 05:57:24.802062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Found device 0 with properties:
pciBusID: 0000:af:00.0 name: NVIDIA A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.45GiB deviceMemoryBandwidth: 1.41TiB/s
2023-02-03 05:57:24.802095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-02-03 05:57:24.802132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 05:57:24.802144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-02-03 05:57:24.802156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-02-03 05:57:24.802168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-02-03 05:57:24.802181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-02-03 05:57:24.802192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-02-03 05:57:24.802205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-02-03 05:57:24.802201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Found device 0 with properties:
pciBusID: 0000:d8:00.0 name: NVIDIA A100-PCIE-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.45GiB deviceMemoryBandwidth: 1.41TiB/s
2023-02-03 05:57:24.802223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-02-03 05:57:24.802257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 05:57:24.802280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-02-03 05:57:24.802294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-02-03 05:57:24.802306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-02-03 05:57:24.802319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-02-03 05:57:24.802331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-02-03 05:57:24.802343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-02-03 05:57:24.805686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1888] Adding visible gpu devices: 0
2023-02-03 05:57:24.805729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-02-03 05:57:24.805831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1888] Adding visible gpu devices: 1
2023-02-03 05:57:24.805859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-02-03 05:57:25.641719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1287] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-02-03 05:57:25.641765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293]      0
2023-02-03 05:57:25.641772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1306] 0:   N
2023-02-03 05:57:25.646476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 37800 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:af:00.0, compute capability: 8.0)
2023-02-03 05:57:25.652653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1287] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-02-03 05:57:25.652700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293]      1
2023-02-03 05:57:25.652707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1306] 1:   N
2023-02-03 05:57:25.657622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 37800 MB memory) -> physical GPU (device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:d8:00.0, compute capability: 8.0)
I0203 05:57:25.676026 140737349957440 run_pretraining.py:123] init_lr = 0.001500
I0203 05:57:25.682729 140737349957440 run_pretraining.py:123] init_lr = 0.001500
WARNING:tensorflow:
The following Variables were used a Lambda layer's call (lambda_2), but
are not present in its tracked objects:
  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 1024) dtype=float32>
It is possible that this is intended behavior, but it is more likely
an omission. This is a strong indication that this layer should be
formulated as a subclassed Layer rather than a Lambda layer.
W0203 05:57:29.200984 140737349957440 core.py:966]
The following Variables were used a Lambda layer's call (lambda_2), but
are not present in its tracked objects:
  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 1024) dtype=float32>
It is possible that this is intended behavior, but it is more likely
an omission. This is a strong indication that this layer should be
formulated as a subclassed Layer rather than a Lambda layer.
WARNING:tensorflow:
The following Variables were used a Lambda layer's call (lambda_2), but
are not present in its tracked objects:
  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 1024) dtype=float32>
It is possible that this is intended behavior, but it is more likely
an omission. This is a strong indication that this layer should be
formulated as a subclassed Layer rather than a Lambda layer.
W0203 05:57:29.272504 140737349957440 core.py:966]
The following Variables were used a Lambda layer's call (lambda_2), but
are not present in its tracked objects:
  <tf.Variable 'word_embeddings/embeddings:0' shape=(30522, 1024) dtype=float32>
It is possible that this is intended behavior, but it is more likely
an omission. This is a strong indication that this layer should be
formulated as a subclassed Layer rather than a Lambda layer.
decayed_learning_rate_at_crossover_point = 1.500000e-03, adjusted_init_lr = 1.500000e-03
decayed_learning_rate_at_crossover_point = 1.500000e-03, adjusted_init_lr = 1.500000e-03





2023-02-03 05:57:58.196798: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-02-03 05:57:58.211253: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2023-02-03 05:57:59.110056: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-02-03 05:57:59.124726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2023-02-03 05:57:59.764341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff904001410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-02-03 05:57:59.764417: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0
2023-02-03 05:57:59.764442: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100-PCIE-40GB, Compute Capability 8.0
2023-02-03 05:57:59.999380: I tensorflow/compiler/jit/xla_compilation_cache.cc:337] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-02-03 05:58:00.720522: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff8b4001410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-02-03 05:58:00.720594: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0
2023-02-03 05:58:00.720622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100-PCIE-40GB, Compute Capability 8.0
2023-02-03 05:58:00.937379: I tensorflow/compiler/jit/xla_compilation_cache.cc:337] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.




2023-02-03 05:59:08.579223: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1642] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2023-02-03 05:59:12.747219: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1642] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2023-02-03 05:59:16.766041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 05:59:17.414011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11


2023-02-03 05:59:21.527002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11


2023-02-03 05:59:22.167250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11


I0203 06:22:52.553852 140737349957440 model_training_utils.py:523] Saved checkpoint to /results/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840_230203055722/phase_1/ckpt-1
I0203 06:22:52.563970 140737349957440 model_training_utils.py:538] Step: 100 Lr 7.575e-05 Loss scale 32768
I0203 06:22:52.564061 140737349957440 model_training_utils.py:539] Train Step: 100/7038  / loss = 10.353649139404297 / time = 1516.255 sec  masked_lm_accuracy = 0.036602  lm_example_loss = 16.000000  next_sentence_accuracy = 0.551070  next_sentence_loss = 1.000000
I0203 06:22:52.564102 140737349957440 model_training_utils.py:540] Perf 506.51
I0203 06:47:43.378864 140737349957440 model_training_utils.py:523] Saved checkpoint to /results/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840_230203055722/phase_1/ckpt-2
I0203 06:47:43.393725 140737349957440 model_training_utils.py:538] Step: 200 Lr 0.0001515 Loss scale 32768
I0203 06:47:43.393826 140737349957440 model_training_utils.py:539] Train Step: 200/7038  / loss = 9.26272964477539 / time = 1485.074 sec  masked_lm_accuracy = 0.070117  lm_example_loss = 16.000000  next_sentence_accuracy = 0.608391  next_sentence_loss = 1.000000
I0203 06:47:43.393873 140737349957440 model_training_utils.py:540] Perf 517.15



===========================
2023-02-03 04:58:26.700652: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
Traceback (most recent call last):
  File "/workspace/bert_tf2/run_pretraining.py", line 207, in <module>
    app.run(main)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/workspace/bert_tf2/run_pretraining.py", line 203, in main
    run_bert_pretrain(strategy)
  File "/workspace/bert_tf2/run_pretraining.py", line 157, in run_bert_pretrain
    return run_customized_training(
  File "/workspace/bert_tf2/run_pretraining.py", line 124, in run_customized_training
    trained_model = model_training_utils.run_customized_training_loop(
  File "/workspace/bert_tf2/official/modeling/model_training_utils.py", line 506, in run_customized_training_loop
    train_steps(train_iterator,
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py", line 2942, in __call__
    return graph_function._call_flat(
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py", line 555, in call
    outputs = execute.execute(
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.
         [[{{node cluster_13_1/merge_oidx_0/_60}}]] [Op:__inference_train_steps_132767]

Function call stack:
train_steps


===================================================================
2023-02-03 03:01:06.704637: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1642] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2023-02-03 03:01:07.516794: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1642] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2023-02-03 03:01:08.473505: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1642] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2023-02-03 03:01:08.722048: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1642] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2023-02-03 03:01:13.241155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 03:01:14.217943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 03:01:14.499781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-02-03 03:01:14.949386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-02-03 03:01:15.070425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 03:01:15.653060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-02-03 03:01:15.981874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-02-03 03:01:16.816955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11



======================================================
I0202 05:01:13.666598 140737349957440 model_training_utils.py:523] Saved checkpoint to /results/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840_230202043547/phase_1/ckpt-1
I0202 05:01:13.687793 140737349957440 model_training_utils.py:538] Step: 100 Lr 7.575e-05 Loss scale 32768
I0202 05:01:13.687882 140737349957440 model_training_utils.py:539] Train Step: 100/7038  / loss = 10.430100440979004 / time = 1511.716 sec  masked_lm_accuracy = 0.037829  lm_example_loss = 16.000000  next_sentence_accuracy = 0.543987  next_sentence_loss = 1.000000
I0202 05:01:13.687921 140737349957440 model_training_utils.py:540] Perf 508.03




I0202 05:25:58.336649 140737349957440 model_training_utils.py:523] Saved checkpoint to /results/tf_bert_pretraining_lamb_large_fp16_gbs17680_gbs23840_230202043547/phase_1/ckpt-2
I0202 05:25:58.344990 140737349957440 model_training_utils.py:538] Step: 200 Lr 0.0001515 Loss scale 32768
I0202 05:25:58.345090 140737349957440 model_training_utils.py:539] Train Step: 200/7038  / loss = 9.3572998046875 / time = 1479.187 sec  masked_lm_accuracy = 0.068735  lm_example_loss = 16.000000  next_sentence_accuracy = 0.603206  next_sentence_loss = 1.000000
I0202 05:25:58.345143 140737349957440 model_training_utils.py:540] Perf 519.21




================================================
Let me break down each step of the data preprocessing implemented by Nvidia's Deep Learning examples Tensorflow BERT:

Tokenization: This step involves breaking down the input text into individual tokens, where each token represents a word or punctuation. The tokenization is performed using the tokenizer provided by the BERT library, which uses a vocabulary file containing the most common words and subwords in the training data.

Input Encoding: After tokenization, each token is then assigned a unique numerical representation, called an ID. This encoding is used to feed the input data into the deep learning model. BERT uses a specific input encoding scheme, known as the BERT input encoding, which includes additional information such as the position of the tokens within the sequence and the sentence segment information.

Padding: To ensure that all input sequences have the same length, the shorter sequences are padded with zeros. The padding is done to the right side of the sequence.

Masking: BERT uses a technique called masking, where some of the tokens in the input sequence are masked, or replaced with a special token [MASK]. The purpose of masking is to predict the original token from the masked token, so the model learns to understand the context of the words in the sequence.

Batch preparation: The input data is then divided into smaller batches, where each batch contains a certain number of samples. The number of samples in a batch is a hyperparameter that can be adjusted based on the available memory and computational resources. The batches are then shuffled to ensure that the model sees a diverse set of input sequences during each training iteration.

These are the main steps involved in the data preprocessing in Nvidia's Deep Learning examples Tensorflow BERT.





Nvidia's Deep Learning examples for TensorFlow BERT implement data preprocessing using the following steps:

Tokenization: The raw text data is tokenized into subwords using WordPiece tokenization.

Mapping tokens to IDs: Each token is then mapped to a unique integer ID.

Padding: The token IDs are then padded to a maximum sequence length to ensure that all input sequences have the same length.

Creating attention masks: An attention mask is created to indicate which tokens in the input sequence should be attended to by the BERT model and which should be ignored.

Generating input tensors: The token IDs and attention masks are then converted into tensors, which are the input to the BERT model.

These steps are performed using the tokenizer and prepare_inputs functions provided by the TensorFlow BERT library. The preprocessed data can then be fed into the BERT model for training or fine-tuning.

============================================================
/usr/bin/python: Error while finding module specification for 'wikiextractor.WikiExtractor' (ModuleNotFoundError: No module named 'wikiextractor')


================================================
BookCorpus: A large-scale dataset of 11,038 books with over 1.4 million unique words. You can download the dataset from the following link: http://yknzhu.wixsite.com/mbweb

Wikipedia English: A large-scale dump of English Wikipedia that can be used to pre-train models. You can download the dataset from the following link: https://dumps.wikimedia.org/enwiki/

SQuAD 2.0: The Stanford Question Answering Dataset version 2.0 which consists of over 130,000 questions and answers. You can download the dataset from the following link: https://rajpurkar.github.io/SQuAD-explorer/

=================================================
run test-photo.py --help
usage: test-photo.py [-h] [-f FOLDER] [-n NUM_IMAGES]

Process multiple images using Photoshop

optional arguments:
  -h, --help            show this help message and exit
  -f FOLDER, --folder FOLDER
                        Folder path where images are located
  -n NUM_IMAGES, --num_images NUM_IMAGES
                        Number of images to process at once





https://docs.google.com/document/d/1Y2irk__m3ZCsDz1NVVhITwj9r8WXUg3jTUVrJxkdNQE/edit#


Chat GPT

Additional preprocessing steps, such as tokenization and batching, are important for preparing the data for training a model like ChatGPT. These steps are typically performed using the map and shuffle functions in TensorFlow 2 and PyTorch.

Tokenization: The process of breaking down the text into individual tokens, such as words or subwords. This is important because the model expects the input to be in the form of tokens, not raw text. Tokenization can be done using various techniques such as splitting the text by whitespaces or using a pre-trained tokenizer.

Batching: The process of grouping the data into smaller chunks or batches. This is important because the model is typically trained on a batch of data at a time, rather than on the entire dataset. Batching allows the model to process multiple examples at once, which can speed up the training process.

Shuffling: The process of randomly shuffling the data before each training epoch. This is important because it helps prevent the model from overfitting to the order of the data. By shuffling the data, each training epoch will be exposed to a different order of examples, which can help the model generalize better.

It's important to note that the tokenization, batching, and shuffling steps can be performed using different functions and libraries depending on the framework you use. The above script is just an example and it can be modified to use different tokenization method or different batch size.




The English Wikipedia dump is a large dataset containing the entire English Wikipedia in an XML format. The dump is released regularly and can be downloaded from the following website:

https://dumps.wikimedia.org/enwiki/

You will have to select the most recent available dump and download the corresponding file. The dump is usually compressed using bz2 or 7z format, you will have to decompress the file to access the data.

It's important to note that the file size can reach several gigabytes, so it may take some time to download the data. Also, the data is in XML format, so you may need to parse the data and perform some preprocessing before using it to train your model.




Generating 13GB/s IOs on storage media and DRAM for a ChatGPT model would be a very demanding task and would likely require a large and complex dataset as well as a powerful machine with a lot of memory and storage resources.

For the dataset, you can use a large corpus of text data such as books, articles or web pages. For example, you can use the English Wikipedia dump that contains several gigabytes of text data.

For the model, you can use a large pre-trained model such as GPT-3 or a similar transformer-based model. These models typically have billions of parameters and require a significant amount of memory and storage.

During training, the data is loaded into the DRAM in batches, where the model processes it to update the model's parameters. The data is also stored on the storage media, such as NVMe SSDs, and is read and written to frequently during the training process.

It's important to note that generating 13GB/s IOs is a very demanding task, and even with a large dataset and a powerful model, it may not be possible to achieve this level of performance on a single machine. You may need to use a cluster of machines or cloud resources to generate this level of IOs.

It's also important to note that generating 13GB/s IOs is a very demanding task and requires a large amount of memory and storage resources, as well as a powerful GPU to process the data quickly enough. It's not a common requirement for most use cases and it's important to consider the cost and feasibility before attempting this task.




=====
mount -t lustre 192.168.61.80@tcp:/lustre /mnt/lustre
======


import argparse
import subprocess
import os, fnmatch, shutil
import re
import parser
from random import seed
from random import randint
from pathlib import Path
from datetime import datetime
from paramiko import client
from distutils.dir_util import copy_tree
from scp import SCPClient, SCPException
import json
from time import sleep
from lib.remote import *
import lib.application as app
import apps.imagenet.imagenet as img

# silent =" 2>/dev/null || true"

# PROJ_DIR = os.path.realpath(os.path.join(__file__, os.pardir))
# APPS_CONF_DIR = os.path.join(PROJ_DIR, "apps")


# seed()

def parse_args():
    parser = argparse.ArgumentParser()

    def csv_str(str1):
        return str1.split(',')
    parser.add_argument('-t','--testname',dest='tname',default='test',help='Testname | e.g. mytest')
    parser.add_argument('-n','--num',dest='num',default=1,type=int,help='Number of tenants | e.g. 2')
    # parser.add_argument('-m','--master',dest='m_id',required=True,type=csv_str,help='Server | e.g. kvm-1,kvm-2')
    parser.add_argument('-s','--servers',dest='s_id',required=True,type=csv_str,help='Server | e.g. kvm-1,kvm-2')
    parser.add_argument('-c','--clients',dest='c_id',required=True,type=csv_str,help='Clients | e.g. kvm-1,kvm-2')
    parser.add_argument('-d','--device',dest='d_id',default='sdb,sdb,sdb,sdb',type=csv_str,help='Storage | e.g. sdb,sdb')
    parser.add_argument('-mt','--mount',dest='mnt',required=False,type=str,help='Dataset Mountpath | e.g. /mnt/lustre/cosmo')
    parser.add_argument('-g','--gpu',dest='gpu',required=False,help='No. of GPUs')
    parser.add_argument('-proc','--procs',dest='procs',required=False,help='No. of processes or tasks')
    parser.add_argument('-th','--threads',dest='th',required=False,help='Number of threads for Pre-processing')
    parser.add_argument('-ct','--ctrace',dest='ctrace',action='store_true',help='Run Ctrace if flag enabled')
    
    # TODO currently shared account id/password. it needs to change to multiple account and password
    parser.add_argument('-u','--user',dest='user',default='root',help='DevClous Autorun server account | e.g. root')
    parser.add_argument('-p','--password',dest='password',default='password',help='DevCloud Autorun server account | e.g. password')

    args = parser.parse_args()
    return args


def main():
    # Get working directory(absolute)
    cwd = os.getcwd()

    # Collect arguments
    args = parse_args()
    dev = args.d_id
    node = len(args.c_id)
    clients = " ".join(args.c_id)
    gpu = args.gpu
    procs = args.procs
    th = args.th
    master = '192.168.61.88'
    

    
    # Initialize conn in servers
    brokers = [RemoteConn(svr) for svr in args.s_id]
    #Initialize conn in clients
    client_conn = [RemoteConn(svr) for svr in args.c_id]
    # Initialize conn in master
    master_conn = RemoteConn(master)
    
    
    # Init variables
    respath = init_test(args.tname, cwd, f'{cwd}/apps/imagenet/yaml')
    respath_imagenet = mkdir_p(respath,'stage1')
    print("respath :", respath)
    yamlpath = os.path.join(respath, 'yaml')
    ns = f'{args.tname}-imagenet'

    
    # Imagenet Pre-run setup
    pre_imagenet_mkdir = img.Imagenet('imagenet', clients, ns, yamlpath, master_conn)
    pre_imagenet_mkdir.imagenet_load_bm(master_conn)
    
    # Start Imagenet Pre-Processing - Stage 1
    print(f'Loading benchmark.... Load Phase')
    # load_imagenet = img.Imagenet('imagenet', clients, ns, yamlpath)
    # load_imagenet.imagenet_load_bm(master_conn)
    

if __name__=='__main__':
    main()


========

새해 복 많이 받으시고, 부디 건강하시고, 가족 모두 행복한 한해 되시길 기원합니다.

=====================
[root@bright88 democratic-csi]# cat examples/nfs-client.yaml
# driver only works with 1.16+
csiDriver:
  # should be globally unique for a given cluster
  name: "org.democratic-csi.nfs-client"

storageClasses:
- name: nfs-client
  defaultClass: false
  reclaimPolicy: Delete
  volumeBindingMode: Immediate
  allowVolumeExpansion: false
  parameters:
    fsType: nfs

  mountOptions:
  - noatime
  - nfsvers=3
  secrets:
    provisioner-secret:
    controller-publish-secret:
    node-stage-secret:
    node-publish-secret:
    controller-expand-secret:

# if your cluster supports snapshots you may enable below
volumeSnapshotClasses: []
#- name: nfs-client
#  secrets:
#    snapshotter-secret:


driver:
  config:
    # please see the most up-to-date example of the corresponding config here:
    # https://github.com/democratic-csi/democratic-csi/tree/master/examples
    # YOU MUST COPY THE DATA HERE INLINE!
    driver: nfs-client
    instance_id:
    nfs:
      shareHost: 192.168.61.89
      shareBasePath: "/mnt/lustre"
      # shareHost:shareBasePath should be mounted at this location in the controller container
      controllerBasePath: "/mnt/lustre/data"
      dirPermissionsMode: "0777"
      dirPermissionsUser: root
      dirPermissionsGroup: root
    #...

# There are 4 different approaches to installing the driver
# 1: Run the controller service separated from the node service, mount the base share into the controller pod at run time
# 2. Run the controller service separated from the node service, use an existing hostPath mount of the base share from the node in the controller pod
# 3. Run the controller service jointly with the node service, mount the base share into the node pod at run time
# 4. Run the controller service jointly with the node service, use an existing hostPath mount of the base share from the node in the node pod
#
# Uncomment the lines/sections below appropriate for your desired use-case

controller:
  enabled: true

  externalResizer:
    enabled: false

  # For Options 1 and 2
  strategy: deployment

  # For Option 1
  #hostNetwork: true
  #hostIPC: true

  # For Options 3 and 4
  #strategy: node


# Option 1
# do this if the nodes do NOT already have the base volume mounted out-of-band from k8s
#  driver:
#    securityContext:
#      allowPrivilegeEscalation: true
#      capabilities:
#        add:
#        - SYS_ADMIN
#      privileged: true
#    lifecycle:
#      postStart:
#        exec:
#          command: ["/bin/sh", "-c", "mkdir -p <controllerBasePath>; mount <shareHost>:<shareBasePath> <controllerBasePath>"]
#      preStop:
#        exec:
#          command: ["/bin/sh","-c","umount <controllerBasePath>"]

# Option 2
# do this if all nodes DO have the base volume mounted out-of-band from k8s
  driver:
    securityContext:
      allowPrivilegeEscalation: true
      capabilities:
        add:
        - SYS_ADMIN
      privileged: true

    extraVolumeMounts:
    - name: nfs-storage
      mountPath: /mnt/lustre/data
      mountPropagation: Bidirectional
#
  extraVolumes:
  - name: nfs-storage
    hostPath:
      path: /mnt/lustre
      type: Directory


# Options 3 and 4
#node:

# Option 3
# do this if the nodes do NOT already have the base volume mounted out-of-band from k8s
#  driver:
#    lifecycle:
#      postStart:
#        exec:
#          command: ["/bin/sh", "-c", "mkdir -p <controllerBasePath>; mount <shareHost>:<shareBasePath> <controllerBasePath>"]
#      preStop:
#        exec:
#          command: ["/bin/sh","-c","umount <controllerBasePath>"]

# Option 4
# do this if all nodes DO have the base volume mounted out-of-band from k8s
#  driver:
#    extraVolumeMounts:
#    - name: nfs-storage
#      mountPath: <controllerBasePath>
#      mountPropagation: Bidirectional
#
#  extraVolumes:
#  - name: nfs-storage
#    hostPath:
#      path: /already/mounted/path/to <shareHost>:<shareBasePath>
#      type: Directory




=====
apiVersion: v1
kind: PersistentVolume
metadata:
  annotations:
    pv.kubernetes.io/provisioned-by: org.democratic-csi.nfs-client
  creationTimestamp: "2023-01-20T02:25:38Z"
  finalizers:
  - kubernetes.io/pv-protection
  name: pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
  resourceVersion: "19593411"
  uid: d87f17ae-88bb-4a2d-8666-2fdc96adb1f6
spec:
  accessModes:
  - ReadWriteOnce
  capacity:
    storage: 200Gi
  claimRef:
    apiVersion: v1
    kind: PersistentVolumeClaim
    name: kf-claim-nfs-2
    namespace: default
    resourceVersion: "19593405"
    uid: 25f0d0be-41de-4a4d-ba21-e39088b86d26
  csi:
    controllerExpandSecretRef:
      name: controller-expand-secret-nfs-client-zfs-nfs-democratic-csi
      namespace: democratic-csi
    controllerPublishSecretRef:
      name: controller-publish-secret-nfs-client-zfs-nfs-democratic-csi
      namespace: democratic-csi
    driver: org.democratic-csi.nfs-client
    fsType: nfs
    nodePublishSecretRef:
      name: node-publish-secret-nfs-client-zfs-nfs-democratic-csi
      namespace: democratic-csi
    nodeStageSecretRef:
      name: node-stage-secret-nfs-client-zfs-nfs-democratic-csi
      namespace: democratic-csi
    volumeAttributes:
      node_attach_driver: nfs
      provisioner_driver: nfs-client
      server: 192.168.61.89
      share: /mnt/lustre/v/pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
      storage.kubernetes.io/csiProvisionerIdentity: 1673590679347-8081-org.democratic-csi.nfs-client
    volumeHandle: pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
  mountOptions:
  - noatime
  - nfsvers=3
  persistentVolumeReclaimPolicy: Delete
  storageClassName: nfs-client
  volumeMode: Filesystem
status:
  phase: Bound



===============================================
apiVersion: v1
kind: Pod
metadata:
  name: mlperf
spec:
  nodeSelector:
    kubernetes.io/hostname: node001
  containers:
  - name: mlperf
    image: 192.168.61.4:5000/nvidia_rn50_mx:0.2
    imagePullPolicy: IfNotPresent
    securityContext:
      privileged: true
    command: ["/bin/sh", "-c"]
    args:
        - "ls /data/imagenet/train-val-recordio-passthrough/"
          #        - "./scripts/prepare_imagenet.sh /data/imagenet/train-val-recordio-passthrough/tiny-imagenet-200 /data/imagenet/train-val-recordio-passthrough/tiny-imagenet-200 40"
    volumeMounts:
    - name: mlperf-volume
      mountPath: /data/imagenet/train-val-recordio-passthrough
  volumes:
  - name: mlperf-volume
    persistentVolumeClaim:
      claimName: kf-claim-nfs-2
  imagePullSecrets:
  - name: regcred





kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: kf-claim-nfs-2
  annotations:
    volume.beta.kubernetes.io/storage-class: "nfs-client"
spec:
  storageClassName: nfs-client
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 200Gi
  nodeSelector:
    kubernetes.io/hostname: node001







[root@bright88 test-scripts]# kubectl describe pv pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
Name:            pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
Labels:          <none>
Annotations:     pv.kubernetes.io/provisioned-by: org.democratic-csi.nfs-client
Finalizers:      [kubernetes.io/pv-protection]
StorageClass:    nfs-client
Status:          Bound
Claim:           default/kf-claim-nfs-2
Reclaim Policy:  Delete
Access Modes:    RWO
VolumeMode:      Filesystem
Capacity:        200Gi
Node Affinity:   <none>
Message:
Source:
    Type:              CSI (a Container Storage Interface (CSI) volume source)
    Driver:            org.democratic-csi.nfs-client
    FSType:            nfs
    VolumeHandle:      pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
    ReadOnly:          false
    VolumeAttributes:      node_attach_driver=nfs
                           provisioner_driver=nfs-client
                           server=192.168.61.89
                           share=/mnt/lustre/v/pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
                           storage.kubernetes.io/csiProvisionerIdentity=1673590679347-8081-org.democratic-csi.nfs-client
Events:                <none>
[root@bright88 test-scripts]# kubectl  get pvc
NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
kf-claim-nfs-2   Bound    pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26   200Gi      RWO            nfs-client     7m15s
[root@bright88 test-scripts]# kubectl describe pvc kf-claim-nfs-2
Name:          kf-claim-nfs-2
Namespace:     default
StorageClass:  nfs-client
Status:        Bound
Volume:        pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
Labels:        <none>
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
               volume.beta.kubernetes.io/storage-class: nfs-client
               volume.beta.kubernetes.io/storage-provisioner: org.democratic-csi.nfs-client
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      200Gi
Access Modes:  RWO
VolumeMode:    Filesystem
Used By:       mlperf
Events:
  Type    Reason                 Age                    From                                                                                                                  Message
  ----    ------                 ----                   ----                                                                                                                  -------
  Normal  Provisioning           7m34s                  org.democratic-csi.nfs-client_zfs-nfs-democratic-csi-controller-f7557ff5d-m6wjc_d73e305d-5952-4ae2-9ba3-b9a36a67df4b  External provisioner is provisioning volume for claim "default/kf-claim-nfs-2"
  Normal  ProvisioningSucceeded  7m34s                  org.democratic-csi.nfs-client_zfs-nfs-democratic-csi-controller-f7557ff5d-m6wjc_d73e305d-5952-4ae2-9ba3-b9a36a67df4b  Successfully provisioned volume pvc-25f0d0be-41de-4a4d-ba21-e39088b86d26
  Normal  ExternalProvisioning   7m33s (x2 over 7m33s)  persistentvolume-controller                                                                                           waiting for a volume to be created, either by external provisioner "org.democratic-csi.nfs-client" or manually created by system administrator





[root@bright88 examples]# kubectl get pods -n democratic-csi
NAME                                                READY   STATUS    RESTARTS   AGE
zfs-nfs-democratic-csi-controller-f7557ff5d-m6wjc   4/4     Running   169        7d15h
zfs-nfs-democratic-csi-node-47vf2                   4/4     Running   0          13d
zfs-nfs-democratic-csi-node-8b7pp                   4/4     Running   461        13d
zfs-nfs-democratic-csi-node-bfzpm                   4/4     Running   0          13d
zfs-nfs-democratic-csi-node-d4pqk                   4/4     Running   0          13d




driver: lustre-client
instance_id:
lustre:
  shareHost: 192.168.61.80
  shareBasePath: "/mnt/lustre"
  # shareHost:shareBasePath should be mounted at this location in the controller container
  controllerBasePath: "/storage"
  dirPermissionsMode: "0777"
  dirPermissionsUser: root
  dirPermissionsGroup: root






MountVolume.MountDevice failed for volume "pvc-7b5b1f73-d73a-4249-bda2-45524313d69a" : rpc error: code = Internal desc = {"code":32,"stdout":"","stderr":"/usr/local/bin/mount: illegal option -- o\nmount.nfs: requested NFS version or transport protocol is not supported\n","timeout":false}

==============================================

Volumes:
  mlperf-volume:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  mlperf-test-node001-pvc
    ReadOnly:   false
  mlperf-log:
    Type:          HostPath (bare host directory volume)
    Path:          /mnt/
    HostPathType:
  host-folder:
    Type:          HostPath (bare host directory volume)
    Path:          /tmp/
    HostPathType:
  kube-api-access-hmb84:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              kubernetes.io/hostname=node001
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age               From               Message
  ----     ------            ----              ----               -------
  Warning  FailedScheduling  18s               default-scheduler  0/7 nodes are available: 7 pod has unbound immediate PersistentVolumeClaims.
  Normal   Scheduled         17s               default-scheduler  Successfully assigned mlperf-test-node001/mlperf to node001
  Warning  FailedMount       1s (x6 over 17s)  kubelet            MountVolume.MountDevice failed for volume "pvc-fd4bde75-15bd-4962-b2c7-8d2232d0bfb2" : rpc error: code = Internal desc = {"code":32,"stdout":"","stderr":"/usr/local/bin/mount: illegal option -- o\nmount.nfs: requested NFS version or transport protocol is not supported\n","timeout":false}




error parsing load.yaml: error converting YAML to JSON: yaml: line 20: did not find expected key



from kubernetes import client, config

class KubernetesWorker:
    def __init__(self):
        # loading kubeconfig
        config.load_kube_config()
        # create an instance of the Kubernetes CoreV1Api
        self.api_instance = client.CoreV1Api()

    def show_nodes(self):
        nodes = self.api_instance.list_node()
        for node in nodes.items:
            print(node.metadata.name)

# Usage
worker = KubernetesWorker()
worker.show_nodes()












slurmstepd: error: pyxis: container start failed with error code: 1
slurmstepd: error: pyxis: printing enroot log file:
slurmstepd: error: pyxis:     /usr/bin/enroot: line 44: HOME: unbound variable
slurmstepd: error: pyxis:     [ERROR] Command not found: nvidia-container-cli, see https://github.com/NVIDIA/libnvidia-container
slurmstepd: error: pyxis:     [ERROR] /etc/enroot/hooks.d/98-nvidia.sh exited with return code 1















[root@bright88 mxnet]# srun --mpi=pmix_v3 -N 1 --ntasks=16  -w node001 --container-image=192.168.61.4:5000#/cosmoflow-nvidia:0.4 --container-name=cosmoflow-preprocess --container-workdir=/mnt/mxnet --container-mounts=/mnt/lustre:/mnt bash tools/init_datasets.sh  /mnt/Cosmo-Small /mnt/processed 16









pyxis: imported docker image: 192.168.61.4:5000#/cosmoflow-nvidia:0.4
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
dpkg: warning: version '4.18.0-372.9.1.el8.x86_64' has bad syntax: invalid character in revision number
[node001:110631] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110633] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110638] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110636] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110640] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110639] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110632] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110642] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110641] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110634] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110644] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110635] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110643] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110630] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110629] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
[node001:110637] PMIX ERROR: ERROR in file gds_ds12_lock_pthread.c at line 168
2023-01-11 15:37:23.068623: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.068624: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.070205: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.072718: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.080399: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.085484: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.085311: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.086233: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.086883: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.088807: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.092000: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.094736: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.097027: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.098812: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.220895: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:23.228529: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-11 15:37:32.585366: F tensorflow/core/platform/statusor.cc:33] Attempting to fetch value instead of handling error INTERNAL: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 85197979648
[node001:110642] *** Process received signal ***
[node001:110642] Signal: Aborted (6)
[node001:110642] Signal code:  (-6)
[node001:110642] [ 0] /usr/lib/x86_64-linux-gnu/libc.so.6(+0x46210)[0x155555370210]
[node001:110642] [ 1] /usr/lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcb)[0x15555537018b]
[node001:110642] [ 2] /usr/lib/x86_64-linux-gnu/libc.so.6(abort+0x12b)[0x15555534f859]
[node001:110642] [ 3] /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x10a461a4)[0x1555331541a4]
[node001:110642] [ 4] /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow17internal_statusor6Helper5CrashERKNS_6StatusE+0x4e)[0x1555331477ce]
[node001:110642] [ 5] /usr/local/lib/python3.8/dist-packages/tensorflow/python/../libtensorflow_framework.so.2(+0x9b3f0b)[0x155521133f0b]
[node001:110642] [ 6] /usr/local/lib/python3.8/dist-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow20BaseGPUDeviceFactory13CreateDevicesERKNS_14SessionOptionsERKSsPSt6vectorISt10unique_ptrINS_6DeviceESt14default_deleteIS8_EESaISB_EE+0x77b)[0x15552113a95b]
[node001:110642] [ 7] /usr/local/lib/python3.8/dist-packages/tensorflow/python/../libtensorflow_framework.so.2(_ZN10tensorflow13DeviceFactory10AddDevicesERKNS_14SessionOptionsERKSsPSt6vectorISt10unique_ptrINS_6DeviceESt14default_deleteIS8_EESaISB_EE+0xad)[0x155520ea5bfd]
[node001:110642] [ 8] /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(TFE_NewContext+0x70)[0x155526cb6050]
[node001:110642] [ 9] /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tfe.so(+0x598f5)[0x15551fb948f5]
[node001:110642] [10] /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tfe.so(+0x55141)[0x15551fb90141]
[node001:110642] [11] python3(PyCFunction_Call+0x59)[0x5f2cc9]
[node001:110642] [12] python3(_PyObject_MakeTpCall+0x150)[0x5f3010]
[node001:110642] [13] python3(_PyEval_EvalFrameDefault+0x5d43)[0x5700f3]
[node001:110642] [14] python3(_PyFunction_Vectorcall+0x1b6)[0x5f5956]
[node001:110642] [15] python3(_PyEval_EvalFrameDefault+0x906)[0x56acb6]
[node001:110642] [16] python3(_PyEval_EvalCodeWithName+0x26a)[0x568d9a]
[node001:110642] [17] python3(_PyFunction_Vectorcall+0x393)[0x5f5b33]
[node001:110642] [18] python3(_PyEval_EvalFrameDefault+0x72f)[0x56aadf]
[node001:110642] [19] python3(_PyFunction_Vectorcall+0x1b6)[0x5f5956]
[node001:110642] [20] python3(_PyEval_EvalFrameDefault+0x72f)[0x56aadf]
[node001:110642] [21] python3(_PyEval_EvalCodeWithName+0x26a)[0x568d9a]
[node001:110642] [22] python3(_PyFunction_Vectorcall+0x393)[0x5f5b33]
[node001:110642] [23] python3(_PyEval_EvalFrameDefault+0x18eb)[0x56bc9b]
[node001:110642] [24] python3(_PyEval_EvalCodeWithName+0x26a)[0x568d9a]
[node001:110642] [25] python3(_PyFunction_Vectorcall+0x393)[0x5f5b33]
[node001:110642] [26] python3(_PyEval_EvalFrameDefault+0x18eb)[0x56bc9b]
[node001:110642] [27] python3(_PyEval_EvalCodeWithName+0x26a)[0x568d9a]
[node001:110642] [28] python3(_PyFunction_Vectorcall+0x393)[0x5f5b33]
[node001:110642] [29] python3(_PyEval_EvalFrameDefault+0x18eb)[0x56bc9b]
[node001:110642] *** End of error message ***
tools/init_datasets.sh: line 7: 110642 Aborted                 (core dumped) python3 -m tools.convert_tfrecord_to_numpy -i ${DATA_SRC_DIR}/train -o ${DATA_DST_DIR}/train -c GZIP -p ${NUM_PROC}
Train set done
slurmstepd: error:  mpi/pmix_v3: _errhandler: node001 [0]: pmixp_client_v2.c:211: Error handler invoked: status = -25, source = [slurm.pmix.259.0:7]
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 259.0 ON node001 CANCELLED AT 2023-01-11T15:37:34 ***
slurmstepd: error:  mpi/pmix_v3: _errhandler: node001 [0]: pmixp_client_v2.c:211: Error handler invoked: status = -25, source = [slurm.pmix.259.0:9]
slurmstepd: error:  mpi/pmix_v3: _errhandler: node001 [0]: pmixp_client_v2.c:211: Error handler invoked: status = -25, source = [slurm.pmix.259.0:10]
srun: error: node001: tasks 0-6,8-15: Killed
